{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s = pd.Series([1,3,5, np.nan, 6,8])\n",
    "#'lista' pandas\n",
    "dates = pd.date_range('20130101', periods = 6)\n",
    "# database in base ad una lista\n",
    "df = pd.DataFrame(np.random.randn(6,4), index=dates, columns=list(\"ABCD\"))\n",
    "#print(df)\n",
    " # dataframe in base ad un dizionario\n",
    "df2 = pd.DataFrame(\n",
    "    {\n",
    "        'A' : 1.0,\n",
    "        'B' : pd.Timestamp('20130102'),\n",
    "        'C' : pd.Series(1, index=list(range(4)), dtype='float32'),\n",
    "        'D' : np.array([3] * 4, dtype='int32'),\n",
    "        'E' : pd.Categorical(['test', 'train', 'test', 'train']),\n",
    "        'F' : 'foo'\n",
    "    }\n",
    ")\n",
    "\n",
    "df.dtypes # tipo colonne\n",
    "\n",
    "df2.head() # prime righe dataframe\n",
    "df.tail(2) # ultime righe \n",
    "df.index # indici righe\n",
    "df.columns # nomi colonne\n",
    "df.to_numpy # trasformare DataFrame in array numpy\n",
    "\n",
    "df2.dtypes\n",
    "df2.to_numpy\n",
    "df.describe() # piccolo riepilogo delle statistiche dei dati\n",
    "#df2.head()\n",
    "#df2.T # trasposizione dei dati le righe diventano colonne e viceversa\n",
    "df.sort_index(axis=1, ascending=False) # ordina inbase ad un asse\n",
    "df.sort_values(by='B')\n",
    "df['A'] # prendo solo la colonna 'A'\n",
    "df[0:3] # seleziono le righe da 0 a 3\n",
    "df[\"20130102\":\"20130104\"] # seleziono le righe da a in base all'indice\n",
    "df.loc[dates[0]] # riga corrispondente a un'etichetta\n",
    "df.loc[:,['A','B']] # seleziono tutte le righe delle colonne a e b\n",
    "df.loc['20130102':'20130104',['A', 'B']] # seleziono dall'eticatta ad etichetta, delle colonne a e b \n",
    "df.loc[dates[0], 'A'] # valore scalare tramite etichetta di riga e colonna\n",
    "df.at[dates[0], 'A'] #stessa cosa sopra\n",
    "df.iloc[3] # righa zero di ogni colonna\n",
    "df.iloc[3:5, 0:2] # dalla riga 3 alla riga 5, dalla colonna 0 alla 2\n",
    "df.iloc[[1,2,4], [0,2]] # prendi tot righe [1,2,4] e tot colonne [0,2]\n",
    "df.iloc[1:3, :] #prendi dalla riga 1 a 3, di tutte le colonne\n",
    "df.iloc[:, 1:3] #prendi tu le righe, dalla colonna 1 a 3\n",
    "df.iloc[1,1] #prendi un preciso valore \n",
    "df.iat[1,1] #stessa cosa di sopra\n",
    "df[df['A'] > 0] # seleziona le righe dove gli elementi di 'A' sono maggiori di 0\n",
    "df[df > 0] # seleziona i valori che sono maggiori di zero\n",
    "df2 = df.copy() # creo un nuovo dataframe che è la copia di df\n",
    "\n",
    "df2['E'] = ['one', 'one', 'two', 'three', 'four', 'three'] # aggiungo una nuova series denominata 'E' e i suoi rispettivi valori\n",
    "df2[df2['E'].isin(['two', 'four'])] # seleziona i valori dove il valore di 'E' sta nella lista passata\n",
    "\n",
    "s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range('20130102', periods=6)) # creo una nuova series s1\n",
    "df['F'] = s1 # creo una nuova colonna nel dataframe chiamata 'F' e gli assegno i valori di s1\n",
    "df.at[dates[0], 'A'] = 0 # imposto i valori in base all'etichetta\n",
    "df.iat[0,1] = 0 # imposto i valori in base alla posizione\n",
    "df.loc[:, 'D'] = np.array([5] * len(df)) # assegno a tutte le righe della nuova colonna 'D' i valori presenti in [5,5,5,5,5,5]\n",
    "\n",
    "df2 = df.copy()\n",
    "df2[df2 > 0] = -df2 # faccio diventare tutto negativo\n",
    "# print(df)\n",
    "# print()\n",
    "#La reindicizzazione consente di modificare/aggiungere/eliminare l'indice su un asse specificato\n",
    "# prendi il df dalla riga 0 alla 4, e tutte le colonne aggiungendo 'E'\n",
    "df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + ['E'])\n",
    "df1.loc[dates[0] : dates[1], 'E'] = 1\n",
    "\n",
    "df1.dropna(how='any') # elimina tutte le righe dove c'è un valore mancante\n",
    "df1.fillna(value=5) # dove il valore è amncante, sostituiscilo con 5\n",
    "pd.isna(df1) # maschera booleana dove i valori sono nan e viceversa\n",
    "\n",
    "df.mean() # calcola il valore medio per ogni colonna\n",
    "df.mean(axis=1) # calcola il valore medio per ogni riga\n",
    "s = pd.Series([1,3,5, np.nan, 6,8], index=dates).shift(2)\n",
    "df.sub(s, axis='index')\n",
    "\n",
    "df.agg(lambda x: np.mean(x) * 5.6) # applica ad ogni colonna la funzione passata\n",
    "df.transform(lambda x: x * 101.2) # applica ad ogni colonna la funzione passata\n",
    "\n",
    "s = pd.Series(np.random.randint(0, 7, size = 10)) # creo una series di 10 numeri con numeri che vanno da 0 a 7\n",
    "s.value_counts() # per ogni numero conta quante ricorrenze ci sono\n",
    "\n",
    "s = pd.Series([\"A\", \"B\", \"C\", \"Aaba\", \"Baca\", np.nan, \"CABA\", \"dog\", \"cat\"])\n",
    "s.str.lower() # converte tutti i valori stringa in minuscolo, altrimenti nan\n",
    "\n",
    "df = pd.DataFrame(np.random.randn(10,4)) # creo un dataframe con 10 righe e 4 colonne di numeri casuali\n",
    "pieces = [df[:3], df[3:7], df[7:]] # creo una matrice contenente il dataframe diviso 3\n",
    "pd.concat(pieces) # concateno i pezzi ottenendo di nuovo il dataframe\n",
    "\n",
    "# creo 2 DataFrame, uno chiamato destro e uno sinistro con una colonna fatta di chiavi e una di valori\n",
    "left = pd.DataFrame({'Key':['foo', 'foo'], 'lval': [1,2]})\n",
    "right = pd.DataFrame({'key':['foo','foo'], 'rval': [4,5]})\n",
    "# Li unisco tramite la colonna key\n",
    "#pd.merge(left, right, on='key') \n",
    "\n",
    "# # CREO un nuovo dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"bar\", \"foo\", \"foo\"],\n",
    "        \"B\": [\"one\", \"one\", \"two\", \"three\", \"two\", \"two\", \"one\", \"three\"],\n",
    "        \"C\": np.random.randn(8),\n",
    "        \"D\": np.random.randn(8),\n",
    "    }\n",
    ")\n",
    "\n",
    "# per ogni elemento di a senza doppioni, dammi la somma dei vaori in c e d\n",
    "df.groupby('A')[['C','D']].sum()\n",
    "\n",
    "# per ogni elemento di a e poi di b, calcola la somma\n",
    "df.groupby(['A', 'B']).sum()\n",
    "#print(df)\n",
    "\n",
    "\n",
    "arrays = [\n",
    "   [\"bar\", \"bar\", \"baz\", \"baz\", \"foo\", \"foo\", \"qux\", \"qux\"],\n",
    "   [\"one\", \"two\", \"one\", \"two\", \"one\", \"two\", \"one\", \"two\"],\n",
    "]\n",
    "# creo un indice composto da 2 indici\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=['first', 'second'])\n",
    "# creo un dataframe con l'indice composto denominando le colonne con a e b\n",
    "df = pd.DataFrame(np.random.randn(8,2), index=index, columns=['A', 'B'])\n",
    "df2 = df[:4]\n",
    "\n",
    "# comprime in livello a pila\n",
    "stacked = df2.stack(future_stack=True)\n",
    "\n",
    "# print(df2)\n",
    "# print()\n",
    "# print(stacked)\n",
    "# print()\n",
    "# print(stacked.unstack())\n",
    "# print()\n",
    "# print(stacked.unstack(1))\n",
    "# print()\n",
    "# print(stacked.unstack(0))\n",
    "# print()\n",
    "# # elimina il precedente stack\n",
    "# #stacked.unstack(1)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"A\": [\"one\", \"one\", \"two\", \"three\"] * 3,\n",
    "        \"B\": [\"A\", \"B\", \"C\"] * 4,\n",
    "        \"C\": [\"foo\", \"foo\", \"foo\", \"bar\", \"bar\", \"bar\"] * 2,\n",
    "        \"D\": np.random.randn(12),\n",
    "        \"E\": np.random.randn(12),\n",
    "    }\n",
    ")\n",
    "\n",
    "pd.pivot_table(df, values='D', index=['A', 'B'], columns=['C'])\n",
    "\n",
    "# creo un range index composta da un periodo di 10 secondi 's' partendo da una determinata data\n",
    "rng = pd.date_range('1/1/2012', periods=10, freq='s')\n",
    "# creo una serie di numeri random da 0 e 500 in base alla lunghezza di rng affiancando l'index\n",
    "ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)\n",
    "ts.resample('5Min').sum()\n",
    "\n",
    "# creo un indice composto da un periodo di 5 giorni 'D'\n",
    "rng = pd.date_range('3/6/2012 00:00', periods = 5, freq='D')\n",
    "\n",
    "ts = pd.Series(np.random.randn(len(rng)), rng)\n",
    "# aggiungo una fase temporale\n",
    "ts_utc = ts.tz_localize('UTC')                \n",
    "#[ts_utc\n",
    "\n",
    "# converto una serie temporale compatibile con i fusi orari in un altro fuso orario\n",
    "ts_utc.tz_convert('US/Eastern')\n",
    "# aggiunta di una durata non fissa\n",
    "rng + pd.offsets.BusinessDay(5)\n",
    "\n",
    "#creo un dataframe con degli indici grezzi\n",
    "df = pd.DataFrame(\n",
    "    {'id':[1,2,3,4,5,6], 'raw_grade' : [\"a\", \"b\", \"b\", \"a\", \"a\", \"e\"]}\n",
    ")\n",
    "# creo la colonna grade che trasforma gli indici grezzi in categorie, togiendo i doppioni\n",
    "df['grade'] = df['raw_grade'].astype('category')\n",
    "# creo una lista di nomi di categorie\n",
    "new_categories = ['very good', 'good', 'very bad']\n",
    "# ridefinisco la colonna grade rinominando i nomi delle categorie\n",
    "df['grade'] = df['grade'].cat.rename_categories(new_categories)\n",
    "# stessa cosa di sopra\n",
    "df['grade'] = df['grade'].cat.set_categories(['very bad', 'bad', 'medium','good', 'very good'])\n",
    "# riordino il dataframe in base ai valori di grade\n",
    "df.sort_values(by='grade')\n",
    "# mostro quanti valori ci sono per ogni categoria comprese quelle con 0\n",
    "df.groupby('grade', observed=False).size()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# chiudo il grafico\n",
    "plt.close('all')\n",
    "\n",
    "ts = pd.Series(np.random.randn(1000), index=pd.date_range('1/1/2000', periods=1000))\n",
    "ts = ts.cumsum()\n",
    "#ts.plot()\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(1000,4), index=ts.index, columns=['A', 'B', 'C', 'D']\n",
    ")\n",
    "\n",
    "df = df.cumsum()\n",
    "plt.figure()\n",
    "df.plot()\n",
    "\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# creo una dataframe\n",
    "df = pd.DataFrame(np.random.randint(0, 5, (10, 5)))\n",
    "# scrivo il dataframe in un csv\n",
    "df.to_csv('foo.csv')\n",
    "# scrivo il dataframe in un file parquet\n",
    "#df.to_parquet(\"foo.parquet\")\n",
    "#leggo ll file parquet\n",
    "#pd.read_parquet('foo.parquet)\n",
    "\n",
    "# scrivo l'excel con sheet 1\n",
    "df.to_excel('foo.xlsx', sheet_name='Sheet1')\n",
    "# leggo il file excel\n",
    "pd.read_excel('foo.xlsx', 'Sheet1', index_col=None, na_values=['NA'])\n",
    "\n",
    "#####\n",
    "# creo un dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \n",
    "     \"BBB\": [10, 20, 30, 40], \n",
    "     \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "\n",
    "# modifico il dataframe assegnando all'elemento di 'BBB' -1 se l'elemento in 'AAA' è >= 5\n",
    "df.loc[df.AAA >= 5, 'BBB'] = -1\n",
    "\n",
    "# modifico il dataframe assegnando agli elementi in 'BBB', 'CCC' 555, se l'elemento in 'AAA' è >= 5\n",
    "df.loc[df['AAA'] >= 5, ['BBB', 'CCC']] = 555\n",
    "# stessa cosa sopra\n",
    "df.loc[df.AAA < 5, ['BBB', 'CCC']] = 2000\n",
    "\n",
    "# creo una maschera che deve essere applicata sopra un dafarame\n",
    "df_mask = pd.DataFrame(\n",
    "    {'AAA':[True] * 4, 'BBB': [False] * 4, 'CCC': [True, False] * 2}\n",
    ")\n",
    "# dove corrisponde sostituisci con -1000\n",
    "df.where(df_mask, -1000)\n",
    "\n",
    "# creo un dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "\n",
    "# creo una colonna 'logic' che come valore ha 'high' se il valore in 'AAA' è maggiore di 5, altrimenti 'low'\n",
    "df['logic'] = np.where(df['AAA'] > 5, 'high', 'low' )\n",
    "\n",
    "# creo un dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "\n",
    "# ritorna solo i valori che rispettano una determinata condizione\n",
    "df[df.AAA <= 5]\n",
    "\n",
    "#stessa cosa sopra\n",
    "df[df.AAA > 5]\n",
    "\n",
    "# creo un dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "\n",
    "# ritorna una serie di solo i valore della colonna 'AAA', dove il valore in BBB è < di 25 e in CCC è >= di -40\n",
    "df.loc[(df['BBB'] < 25) & (df['CCC'] >= -40), 'AAA']\n",
    "\n",
    "# ritorna una serie di solo i valori della colonna 'BBB', dove il valore in 'BBB' è > 25 o in 'CCC' è >= di -40\n",
    "df.loc[(df['BBB'] > 25 ) | (df['CCC'] >= -40), 'AAA']\n",
    "\n",
    "# prendi i valori i valori della colonna 'BBB', dove il valore in 'BBB' è > 25 o in 'CCC' è >= di 75 e sostituiscili con 999 nella colonna 'AAA'\n",
    "df.loc[(df['BBB'] > 25) | (df['CCC'] >= 75), 'AAA'] = 999\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "\n",
    "# creo un valore di riferimento\n",
    "aValue = 43.0\n",
    "# prendo ogni valore in CCC stottraggi il valore di rifermiento e salvo il resto, e poi riordino in base a quello\n",
    "df.loc[(df.CCC - aValue).abs().argsort()]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7], \"BBB\": [10, 20, 30, 40], \"CCC\": [100, 50, -30, -50]}\n",
    ")\n",
    "# creo tre series per ogni colonna, dove i valori sono true o false in base alla condizione\n",
    "Crit1 = df.AAA <= 5.5\n",
    "Crit2 = df.BBB == 10.0\n",
    "Crit3 = df.CCC > -40.0\n",
    "# creo una serie unendo le varie series sommando i false e true\n",
    "AllCrit = Crit1 & Crit2 & Crit3\n",
    "df[AllCrit]\n",
    "\n",
    "#\n",
    "import functools\n",
    "# Creo una lista con le tre series\n",
    "CritList = [Crit1, Crit2, Crit3]\n",
    "# uso funtoools. che confronta i valori tra false e true\n",
    "AllCrit = functools.reduce(lambda x, y: x & y, CritList)\n",
    "#  creo un dataframe con i risultati\n",
    "df[AllCrit]\n",
    "# prendo tutti i valori in AAA che sono minori o uguali a 6 e dove l'indice '0,2,4'\n",
    "df[(df.AAA <= 6) & (df.index.isin([0,2,4]))]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7],\n",
    "     \"BBB\": [10, 20, 30, 40], \n",
    "     \"CCC\": [100, 50, -30, -50]},\n",
    "    index=[\"foo\", \"bar\", \"boo\", \"kar\"],\n",
    ")\n",
    "\n",
    "# seleziono da''indice bar a kar\n",
    "df.loc['bar':'kar'] # label\n",
    "# seleziona gli elemnti dalla riga 0 alla 3 esclusa\n",
    "df[0:3]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [4, 5, 6, 7],\n",
    "     \"BBB\": [10, 20, 30, 40], \n",
    "     \"CCC\": [100, 50, -30, -50]},\n",
    ")\n",
    "\n",
    "# creo un data frame con un dataframe già esistente ma con un indice diversp\n",
    "df2 = pd.DataFrame(data=df, index=[1,2,3,4]) # Note index starts at 1\n",
    "#df2\n",
    "df2.iloc[1:3] # Position-oriented\n",
    "df2.loc[1:3] # Label-oriented\n",
    "\n",
    "# prendi i valori che non sono <= di 6 e gli indici non siano nella lista\n",
    "df[~((df.AAA <= 6) & (df.index.isin([0,2,4])))]\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"AAA\": [1, 2, 1, 3], \n",
    "    \"BBB\": [1, 1, 2, 2], \n",
    "    \"CCC\": [2, 1, 3, 1]})\n",
    "\n",
    "# prendo i nomi delle colonee\n",
    "source_cols = df.columns # Or some subset would work too\n",
    "# creo una lista che per ogni colonna creo una colonna con lo stesso nome aggiungendo '_cat'\n",
    "new_cols = [str(x) + '_cat' for x in source_cols]\n",
    "# creo tre categorie\n",
    "categories = {1:'Alpha', 2:'Beta', 3:'Charlie'}\n",
    "# creo una nuova colonna che in base al valore delle colonne standard, assegna una categoria\n",
    "df[new_cols] = df[source_cols].map(categories.get)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\"AAA\": [1, 1, 1, 2, 2, 2, 3, 3], \n",
    "     \"BBB\": [2, 1, 3, 4, 5, 1, 2, 3]}\n",
    ")\n",
    "\n",
    "# per ottenere l'indice dei minimo\n",
    "df.loc[df.groupby('AAA')['BBB'].idxmin()]\n",
    "# ordina, quindi prendi il primo di ciascuno, stessi risultati ma con indice diverso\n",
    "df.sort_values(by='BBB').groupby('AAA', as_index=False).first()\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"row\": [0, 1, 2],\n",
    "        \"One_X\": [1.1, 1.1, 1.1],\n",
    "        \"One_Y\": [1.2, 1.2, 1.2],\n",
    "        \"Two_X\": [1.11, 1.11, 1.11],\n",
    "        \"Two_Y\": [1.22, 1.22, 1.22],\n",
    "    }\n",
    ")\n",
    "# faccio diventare l'index principale la colonna row\n",
    "df = df.set_index('row')\n",
    "# creo un multi indice dividendo i nomi tramite _, e per ognuno assegna un sotto indice\n",
    "df.columns = pd.MultiIndex.from_tuples([tuple(c.split('_')) for c in df.columns])\n",
    "# cambia forma al dataframe\n",
    "df = df.stack(0, future_stack=True).reset_index(1)\n",
    "# rinomino le colonne\n",
    "df.columns = ['Sample', 'All_X', 'All_y']\n",
    "\n",
    "# creo un multiindice composto da 3 valori e ognuno composto da 2 sottoindici\n",
    "cols = pd.MultiIndex.from_tuples(\n",
    "    [(x,y) for x in ['A', 'B', 'C'] for y in ['0', 'I']]\n",
    ")\n",
    "# creo un dataframe composto da valori casuali tra 2 e 6 e da 2 indici, n e m, e come colonne i multindici \n",
    "df = pd.DataFrame(np.random.randn(2,6), index=['n','m'], columns=cols)\n",
    "# divido ogni elemento della riga in base al valore corrispondente nella colonna c\n",
    "df = df.div(df['C'], level=1)\n",
    "\n",
    "#creo una lista di tuple\n",
    "coords = [('AA', 'one'), ('AA', 'six'), ('BB', 'one'), ('BB', 'two'), ('BB', 'six')]\n",
    "# creo un multiindice passando la lista di tuple\n",
    "index = pd.MultiIndex.from_tuples(coords)\n",
    "# creo un dataframe con tre colonne\n",
    "    # La prima con il primo elemento delle tuple (primo livelo)\n",
    "    # La seconda con il secondo elemento delle tuple (secondo livello)\n",
    "    # La terza con valori passati in una lista (terzo livello)\n",
    "\n",
    "df = pd.DataFrame([11,22,33,44,55], index, ['MyData'] )\n",
    "# prendo la sezione trasversale del 1° livello e del 1° asse\n",
    "# prendo i valori sottostanti al primo livello nell'indice 'BB'\n",
    "df.xs('BB', level=0, axis=0)\n",
    "# prendo i valori del seocndo livello che hanno come indice 'six'\n",
    "df.xs('six', level=1, axis=0)\n",
    "\n",
    "import itertools\n",
    "# creo una lista di tuple con le varie combinazioni\n",
    "index = list(itertools.product(['Ada', 'Quinn', 'Violet'], ['Comp', 'Math', 'Sci']))\n",
    "# creo una lista di tuple con le varie combinazioni\n",
    "headr = list(itertools.product(['Exam', 'Labs'], ['I', 'II']))\n",
    "# creo un indice indx multiindice che come valori ha una lista di tuple index\n",
    "indx = pd.MultiIndex.from_tuples(index, names=['Student', 'Course'])\n",
    "# creo un multiindice cols che come valori ha una lista di tuple headr\n",
    "cols = pd.MultiIndex.from_tuples(headr) # Notice these are un-named\n",
    "# creo una lista di liste\n",
    "data = [[70 + x + y + (x*y) %3 for x in range(4)] for y in range(9)]\n",
    "# ora creo il dataframe pssando i valori, il primo livello di indice ed il secondo\n",
    "df = pd.DataFrame(data, indx, cols)\n",
    "All = slice(None)\n",
    "# prendo i valori dello studente 'Violet'\n",
    "df.loc['Violet']\n",
    "# prendo solo i valori del corso di math\n",
    "df.loc[(All, 'Math'), All]\n",
    "# prendo gli studenti da ada a queen dove il corso è math\n",
    "df.loc[(slice('Ada', 'Quinn'), 'Math'), All]\n",
    "# \n",
    "df.loc[(All, 'Math'), (All, 'II')]\n",
    "\n",
    "# ordino per una colonna o per un elenco\n",
    "df.sort_values(by=('Labs', 'II'), ascending=False)\n",
    "\n",
    "# DATI MANCANTI\n",
    "# Creo un dataframe\n",
    "    # indice 6 giorni\n",
    "df = pd.DataFrame(\n",
    "    np.random.randn(6,1),\n",
    "    index = pd.date_range('2013-08-01', periods=6, freq='B'),\n",
    "    columns = list('A'),\n",
    ")\n",
    "# modifico il valore alla posizione 3 della colonna a con nan\n",
    "df.loc[df.index[3], 'A'] = np.nan\n",
    "\n",
    "df.bfill()\n",
    "\n",
    "# RAGGRUPPAMENTO\n",
    "# creo un dataframe\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"animal\": \"cat dog cat fish dog cat cat\".split(),\n",
    "        \"size\": list(\"SSMMMLL\"),\n",
    "        \"weight\": [8, 10, 11, 1, 20, 12, 12],\n",
    "        \"adult\": [False] * 5 + [True] * 2,\n",
    "    }\n",
    ")\n",
    "\n",
    "# raggruppa gli animali in base alla taglia e al peso\n",
    "df.groupby(\"animal\").apply(lambda subf: subf[\"size\"][subf[\"weight\"].idxmax()])#, include_groups=False)\n",
    "#raggruppba in base ad 'animal'\n",
    "gb = df.groupby('animal')\n",
    "# estrai solo 'cat'\n",
    "gb.get_group('cat')\n",
    "\n",
    "def GrowUp(x):\n",
    "    avg_weight = sum(x[x[\"size\"] == \"S\"].weight * 1.5)\n",
    "    avg_weight += sum(x[x[\"size\"] == \"M\"].weight * 1.25)\n",
    "    avg_weight += sum(x[x[\"size\"] == \"L\"].weight)\n",
    "    avg_weight /= len(x)\n",
    "    return pd.Series([\"L\", avg_weight, True], index=[\"size\", \"weight\", \"adult\"])\n",
    "\n",
    "# per ogni elemnto nel dataframe applica la funzione grouwup\n",
    "expected_df = gb.apply(GrowUp)#, include_groups=False)\n",
    "# ritorna un dataframe con la somma del peso medio per ciascun elemento\n",
    "#expected_df\n",
    "\n",
    "#creo una lista di 10 elementi\n",
    "S = pd.Series([i / 100.0 for i in range(1,11)])\n",
    "# definisco una fuinzione che prende 2 valori e ritorna il prodotto tra x e y+1\n",
    "def cum_ret(x,y):\n",
    "    return x * (1+y)\n",
    "\n",
    "# definisco una funzione che prende 1 valore\n",
    "def red(x):\n",
    "    return functools.reduce(cum_ret, x, 1.0)\n",
    "# applico le funzioni a s\n",
    "S.expanding().apply(red, raw=True)\n",
    "\n",
    "# Creo un dataframe\n",
    "df = pd.DataFrame({'A': [1, 1, 2, 2], \"B\": [1, -1, 1, 2]})\n",
    "# creo gb, raggruppando per a\n",
    "gb = df.groupby('A')\n",
    "\n",
    "# creo una funzione che prend eun valore, in base alla condizione, la maschera è vera o falsa\n",
    "# sostituzione di alcuni valori con la media del resto\n",
    "def replace(g):\n",
    "    mask = g < 0\n",
    "    return g.where(~mask, g[~mask].mean())\n",
    "# applica a gb\n",
    "gb.transform(replace)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"code\": [\"foo\", \"bar\", \"baz\"] * 2,\n",
    "        \"data\": [0.16, -0.21, 0.33, 0.45, -0.59, 0.62],\n",
    "        \"flag\": [False, True] * 3,\n",
    "    }\n",
    ")\n",
    "# ordina i dati in base ai dati aggregati\n",
    "code_groups = df.groupby('flag')\n",
    "agg_n_sort_order = code_groups[['data']].transform('sum').sort_values(by='data')\n",
    "sorted_df = df.loc[agg_n_sort_order.index]\n",
    "sorted_df\n",
    "\n",
    "# creare più colonne aggregate\n",
    "rng = pd.date_range(start='2014-10-07', periods=10, freq='2min')\n",
    "ts = pd.Series(data=list(range(10)), index=rng)\n",
    "\n",
    "def MyCust(x):\n",
    "    if len(x)> 2:\n",
    "        return x.iloc[1] * 1,234\n",
    "    return pd.NaT\n",
    "\n",
    "mhc = {'Mean':'mean', 'Max':'max', 'Custom':MyCust}\n",
    "ts.resample('5min').apply(mhc)\n",
    "ts\n",
    "\n",
    "# Creare una colonna di conteggio dei valori e riassegnarla al DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\"Color\": \"Red Red Red Blue\".split(), \"Value\": [100, 150, 50, 50]}\n",
    ")\n",
    "#print(df)\n",
    "df['Counts'] = df.groupby(['Color']).transform(len)\n",
    "\n",
    "# Spostare gruppi di valori in una colonna in base all'indice\n",
    "df = pd.DataFrame(\n",
    "    {\"line_race\": [10, 10, 8, 10, 10, 8], \"beyer\": [99, 102, 103, 103, 88, 100]},\n",
    "    index=[\n",
    "        \"Last Gunfighter\",\n",
    "        \"Last Gunfighter\",\n",
    "        \"Last Gunfighter\",\n",
    "        \"Paynter\",\n",
    "        \"Paynter\",\n",
    "        \"Paynter\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "df['beyer_shifted'] = df.groupby(level=0)['beyer'].shift(1)\n",
    "\n",
    "# seleziona la riga con il valore massimo di ogni gruppo\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"host\": [\"other\", \"other\", \"that\", \"this\", \"this\"],\n",
    "        \"service\": [\"mail\", \"web\", \"mail\", \"mail\", \"web\"],\n",
    "        \"no\": [1, 2, 1, 2, 1],\n",
    "    }\n",
    ").set_index([\"host\", \"service\"])\n",
    "#print(df)\n",
    "mask = df.groupby(level=0).agg('idxmax')\n",
    "df_count = df.loc[mask['no']].reset_index()\n",
    "\n",
    "# raggruppamento come itertools.groupby di python\n",
    "df = pd.DataFrame([0,1,0,1,1,1,0,1,1], columns=['A'])\n",
    "df['A'].groupby((df['A'] != df['A'].shift()).cumsum()).groups\n",
    "df['A'].groupby((df['A'] != df['A'].shift()).cumsum()).cumsum()\n",
    "\n",
    "# divisione di un fotogramma\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Case\": [\"A\", \"A\", \"A\", \"B\", \"A\", \"A\", \"B\", \"A\", \"A\"],\n",
    "        \"Data\": np.random.randn(9),\n",
    "    }\n",
    ")\n",
    "\n",
    "dfs = list(\n",
    "    zip(\n",
    "        *df.groupby(\n",
    "            (1 * (df['Case'] == 'B'))\n",
    "            .cumsum()\n",
    "            .rolling(window=3, min_periods=1)\n",
    "            .median()\n",
    "        )\n",
    "    )\n",
    ")[-1]\n",
    "\n",
    "dfs[0]\n",
    "dfs[1]\n",
    "dfs[2]\n",
    "\n",
    "# Somme parziali e subtotali\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Province\": [\"ON\", \"QC\", \"BC\", \"AL\", \"AL\", \"MN\", \"ON\"],\n",
    "        \"City\": [\n",
    "            \"Toronto\",\n",
    "            \"Montreal\",\n",
    "            \"Vancouver\",\n",
    "            \"Calgary\",\n",
    "            \"Edmonton\",\n",
    "            \"Winnipeg\",\n",
    "            \"Windsor\",\n",
    "        ],\n",
    "        \"Sales\": [13, 6, 16, 8, 4, 3, 1],\n",
    "    }\n",
    ")\n",
    "\n",
    "table = pd.pivot_table(\n",
    "    df,\n",
    "    values=['Sales'],\n",
    "    index=[\"Province\"],\n",
    "    columns=[\"City\"],\n",
    "    aggfunc=\"sum\",\n",
    "    margins=True,\n",
    ")\n",
    "\n",
    "table.stack('City', future_stack=True)\n",
    "\n",
    "# frequency table like plyr in R\n",
    "grades = [48, 99, 75, 80, 42, 80, 72, 68, 36, 78]\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": [\"x%d\" % r for r in range(10)],\n",
    "        \"Gender\": [\"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"F\", \"M\", \"M\", \"M\"],\n",
    "        \"ExamYear\": [\n",
    "            \"2007\",\n",
    "            \"2007\",\n",
    "            \"2007\",\n",
    "            \"2008\",\n",
    "            \"2008\",\n",
    "            \"2008\",\n",
    "            \"2008\",\n",
    "            \"2009\",\n",
    "            \"2009\",\n",
    "            \"2009\",\n",
    "        ],\n",
    "        \"Class\": [\n",
    "            \"algebra\",\n",
    "            \"stats\",\n",
    "            \"bio\",\n",
    "            \"algebra\",\n",
    "            \"algebra\",\n",
    "            \"stats\",\n",
    "            \"stats\",\n",
    "            \"algebra\",\n",
    "            \"bio\",\n",
    "            \"bio\",\n",
    "        ],\n",
    "        \"Participated\": [\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"no\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "            \"yes\",\n",
    "        ],\n",
    "        \"Passed\": [\"yes\" if x > 50 else \"no\" for x in grades],\n",
    "        \"Employed\": [\n",
    "            True,\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            False,\n",
    "            True,\n",
    "            True,\n",
    "            False,\n",
    "        ],\n",
    "        \"Grade\": grades,\n",
    "    }\n",
    ")\n",
    "\n",
    "df.groupby('ExamYear').agg(\n",
    "    {\"Participated\": lambda x: x.value_counts()[\"yes\"],\n",
    "        \"Passed\": lambda x: sum(x == \"yes\"),\n",
    "        \"Employed\": lambda x: sum(x),\n",
    "        \"Grade\": lambda x: sum(x) / len(x),\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot pandas DataFrame with year over year data\n",
    "# df = pd.DataFrame(\n",
    "#     {'value': np.random.randn(36)},\n",
    "#     index = pd.date_range('2011-01-01', freq='ME', periods=36),\n",
    "# )\n",
    "# pd.pivot_table(\n",
    "#     df, index=df.index.month, columns=df.index.year, values='value', aggfunc='sum'\n",
    "# )\n",
    "\n",
    "#Rolling apply to organize - Turning embedded lists into a multiindex frame\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"A\": [[2, 4, 8, 16], [100, 200], [10, 20, 30]],\n",
    "        \"B\": [[\"a\", \"b\", \"c\"], [\"jj\", \"kk\"], [\"ccc\"]],\n",
    "    },\n",
    "    index = ['I', 'II', 'III']\n",
    ")\n",
    "\n",
    "def SeriesFromSubList(aList):\n",
    "    return pd.Series(aList)\n",
    "\n",
    "df_orgz = pd.concat(\n",
    "    {ind: row.apply(SeriesFromSubList) for ind, row in df.iterrows()}\n",
    ")\n",
    "\n",
    "# Rolling apply con un dataframe che restituisce una serie\n",
    "df = pd.DataFrame(\n",
    "    data=np.random.randn(2000, 2) / 10000,\n",
    "    index=pd.date_range(\"2001-01-01\", periods=2000),\n",
    "    columns=[\"A\", \"B\"],\n",
    ")\n",
    "\n",
    "def gm(df, const):\n",
    "    v = ((((df[\"A\"] + df[\"B\"]) + 1).cumprod()) - 1) * const\n",
    "    return v.iloc[-1]\n",
    "\n",
    "s = pd.Series(\n",
    "    {\n",
    "        df.index[i]: gm(df.iloc[i: min(i + 51, len(df) - 1)], 5)\n",
    "        for i in range(len(df) - 50)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Rolling apply con un dataframe che restituisce uno scalare\n",
    "rng = pd.date_range(start=\"2014-01-01\", periods=100)\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"Open\": np.random.randn(len(rng)),\n",
    "        \"Close\": np.random.randn(len(rng)),\n",
    "        \"Volume\": np.random.randint(100, 2000, len(rng)),\n",
    "    },\n",
    "    index=rng,\n",
    ")\n",
    "def vwap(bars):\n",
    "    return (bars.Close * bars.Volume).sum() / bars.Volume.sum()\n",
    "\n",
    "\n",
    "window = 5\n",
    "\n",
    "s = pd.concat(\n",
    "    [\n",
    "        (pd.Series(vwap(df.iloc[i: i + window]), index=[df.index[i + window]]))\n",
    "        for i in range(len(df) - window)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# calcolare il primo giorno del mese per ogni voce in un Datetimeindex\n",
    "dates = pd.date_range(\"2000-01-01\", periods=5)\n",
    "\n",
    "dates.to_period(freq=\"M\").to_timestamp()\n",
    "\n",
    "# concatenare due dataframe con indice sovrapposto\n",
    "rng = pd.date_range('2000-01-01', periods=6)\n",
    "df1 = pd.DataFrame(np.random.rand(6,3), index=rng, columns=['A', 'B', 'C'])\n",
    "df1.copy()\n",
    "\n",
    "# self join di in dataframe\n",
    "df = pd.DataFrame(\n",
    "    data={\n",
    "        \"Area\": [\"A\"] * 5 + [\"C\"] * 2,\n",
    "        \"Bins\": [110] * 2 + [160] * 3 + [40] * 2,\n",
    "        \"Test_0\": [0, 1, 0, 1, 2, 0, 1],\n",
    "        \"Data\": np.random.randn(7),\n",
    "    }\n",
    ")\n",
    "\n",
    "df['Test_1'] = df['Test_0'] -1\n",
    "pd.merge(\n",
    "    df,\n",
    "    df,\n",
    "    left_on=[\"Bins\", \"Area\", \"Test_0\"],\n",
    "    right_on=[\"Bins\", \"Area\", \"Test_1\"],\n",
    "    suffixes=(\"_L\", \"_R\")\n",
    ")\n",
    "\n",
    "# plot con pandas\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"stratifying_var\": np.random.uniform(0, 100, 20),\n",
    "        \"price\": np.random.normal(100, 5, 20),\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "df[\"quartiles\"] = pd.qcut(\n",
    "    df[\"stratifying_var\"], 4, labels=[\"0-25%\", \"25-50%\", \"50-75%\", \"75-100%\"]\n",
    ")\n",
    "\n",
    "\n",
    "#df.boxplot(column=\"price\", by=\"quartiles\")\n",
    "\n",
    "# lettura di più file per creare un singolo DataFrame\n",
    "# creo 3 dataframe\n",
    "for i in range(3):\n",
    "    data = pd.DataFrame(np.random.randn(10, 4))\n",
    "    data.to_csv('file_{}.csv'.format(i))\n",
    "# prendo una lista dei file da leggere\n",
    "files = [\"file_0.csv\", \"file_1.csv\", \"file_2.csv\"]\n",
    "# result è il dataframe composto dalla concatenazione dei file\n",
    "result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "import glob\n",
    "\n",
    "import os\n",
    "\n",
    "files = glob.glob(\"file_*.csv\")\n",
    "\n",
    "result = pd.concat([pd.read_csv(f) for f in files], ignore_index=True)\n",
    "\n",
    "#\n",
    "i = pd.date_range('20000101', periods=10000)\n",
    "df = pd.DataFrame({'year':i.year, 'month': i.month, 'day':i.day})\n",
    "df.head()\n",
    "#%timeit pd.to_datetime(df.year * 10000 + df.month * 100 + df.day, format='%Y%m%d')\n",
    "ds = df.apply(lambda x: \"%04d%02d%02d\" % (x[\"year\"], x[\"month\"], x[\"day\"]), axis=1)\n",
    "ds.head()\n",
    "#%timeit pd.to_datetime(ds)\n",
    "\n",
    "#Salta la riga tra l'intestazione e i dati\n",
    "data = \"\"\";;;;\n",
    " ;;;;\n",
    " ;;;;\n",
    " ;;;;\n",
    " ;;;;\n",
    " ;;;;\n",
    ";;;;\n",
    " ;;;;\n",
    " ;;;;\n",
    ";;;;\n",
    "date;Param1;Param2;Param4;Param5\n",
    "    ;m²;°C;m²;m\n",
    ";;;;\n",
    "01.01.1990 00:00;1;1;2;3\n",
    "01.01.1990 01:00;5;3;4;5\n",
    "01.01.1990 02:00;9;5;6;7\n",
    "01.01.1990 03:00;13;7;8;9\n",
    "01.01.1990 04:00;17;9;10;11\n",
    "01.01.1990 05:00;21;11;12;13\n",
    "\"\"\"\n",
    "\n",
    "#passare le righe in modo esplicito per saltare le righe\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "pd.read_csv(\n",
    "    StringIO(data),\n",
    "    sep=';',\n",
    "    skiprows=[11,12],\n",
    "    index_col=0,\n",
    "    parse_dates=True,\n",
    "    header=10\n",
    ")\n",
    "\n",
    "#leggere i nomi delle colonne e quindi i dati\n",
    "\n",
    "pd.read_csv(\n",
    "    StringIO(data), \n",
    "    sep=';',\n",
    "    header=10,\n",
    "    nrows=10).columns\n",
    "\n",
    "columns = pd.read_csv(StringIO(data), sep=\";\", header=10, nrows=10).columns\n",
    "\n",
    "pd.read_csv(\n",
    "    StringIO(data), sep=\";\", index_col=0, header=12, parse_dates=True, names=columns\n",
    ")\n",
    "\n",
    "\n",
    "# elemnti a aforma triangolare inferiore\n",
    "df = pd.DataFrame(np.random.random(size=(100, 5)))\n",
    "\n",
    "corr_mat = df.corr()\n",
    "\n",
    "mask = np.tril(np.ones_like(corr_mat, dtype=np.bool_), k=-1)\n",
    "\n",
    "corr_mat.where(mask)\n",
    "\n",
    "\n",
    "def distcorr(x, y):\n",
    "    n = len(x)\n",
    "    a = np.zeros(shape=(n, n))\n",
    "    b = np.zeros(shape=(n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            a[i, j] = abs(x[i] - x[j])\n",
    "            b[i, j] = abs(y[i] - y[j])\n",
    "    a += a.T\n",
    "    b += b.T\n",
    "    a_bar = np.vstack([np.nanmean(a, axis=0)] * n)\n",
    "    b_bar = np.vstack([np.nanmean(b, axis=0)] * n)\n",
    "    A = a - a_bar - a_bar.T + np.full(shape=(n, n), fill_value=a_bar.mean())\n",
    "    B = b - b_bar - b_bar.T + np.full(shape=(n, n), fill_value=b_bar.mean())\n",
    "    cov_ab = np.sqrt(np.nansum(A * B)) / n\n",
    "    std_a = np.sqrt(np.sqrt(np.nansum(A ** 2)) / n)\n",
    "    std_b = np.sqrt(np.sqrt(np.nansum(B ** 2)) / n)\n",
    "    return cov_ab / std_a / std_b\n",
    "\n",
    "\n",
    "df = pd.DataFrame(np.random.normal(size=(100, 3)))\n",
    "\n",
    "df.corr(method=distcorr)\n",
    "\n",
    "# DeltaTemporali\n",
    "import datetime\n",
    "s = pd.Series(pd.date_range('2012-1-1', periods=3, freq='D'))\n",
    "\n",
    "#Creazione di dati di esempio\n",
    "# import intertools\n",
    "# def expand_grid(data_dict):\n",
    "#     rows = intertools.product(*data_dict.values())\n",
    "#     return pd.DataFrame.from_records(rows, columns=data_dict.keys())\n",
    "\n",
    "# df = expand_grid(\n",
    "#     {'height': [60,70], 'weight': [100, 140, 180], 'sex': ['Male', 'Female']}\n",
    "# )\n",
    "\n",
    "v = s.to_numpy()\n",
    "is_constant = v.shape[0] == 0 or (s[0] == s).all()\n",
    "v = s.dropna().to_numpy()\n",
    "is_constant = v.shape[0] == 0 or (s[0] == s).all()\n",
    "\n",
    "v = s.to_numpy()\n",
    "is_constant = v.shape[0] or (s[0] == s).all() or not pd.notna(v).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Somma: 110\n",
      "Media: 11.0\n",
      "Mediana: 12.0\n",
      "Moda: Più di una moda\n"
     ]
    }
   ],
   "source": [
    "dataset = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20]\n",
    "\n",
    "def somma(lista):\n",
    "    som = 0\n",
    "    for x in lista:\n",
    "        som += x\n",
    "    return som\n",
    "\n",
    "def media(lista):\n",
    "    som = 0\n",
    "    count = 0\n",
    "    for x in lista:\n",
    "        som += x\n",
    "        count += 1\n",
    "    med = som / count\n",
    "    return med\n",
    "\n",
    "def mediana(lista):\n",
    "    lista.sort()\n",
    "    n = len(lista)\n",
    "    if len(lista) % 2 == 0:\n",
    "        med = (lista[n//2 - 1] + lista[n//2 + 1]) / 2\n",
    "    else:\n",
    "        med = lista[n//2]\n",
    "    return med\n",
    "\n",
    "def moda(lista):\n",
    "    frequenze = {}\n",
    "    for x in lista:\n",
    "        if x in frequenze:\n",
    "            frequenze[x] += 1\n",
    "        else:\n",
    "            frequenze[x] = 1\n",
    "    mod = [x for x, k in frequenze.items() if k == max(frequenze.values())]\n",
    "    return mod[0] if len(mod) == 1 else \"Più di una moda\"\n",
    "\n",
    "print('Somma:', somma(dataset))\n",
    "print('Media:', media(dataset))\n",
    "print('Mediana:', mediana(dataset))\n",
    "print('Moda:', moda(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.scatterplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandas_datareader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up dates using datetime module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data, wb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "\n",
    "start = datetime.datetime(2006, 1, 1)\n",
    "end = datetime.datetime(2016, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreiveing Data from all the listed bank above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank of America\n",
    "BAC = data.DataReader('BAC', 'yahoo', start, end)\n",
    "\n",
    "# CitiGroup\n",
    "C = data.DataReader('C', 'yahoo', start, end)\n",
    "\n",
    "# Goldman Sachs\n",
    "GS = data.DataReader('GS', 'yahoo', start, end)\n",
    "\n",
    "# JPMorgan Chase\n",
    "JPM = data.DataReader('JPM', 'yahoo', start, end)\n",
    "\n",
    "# Morgan Stanley\n",
    "MS = data.DataReader('MS', 'yahoo', start, end)\n",
    "\n",
    "# Wells Fargo\n",
    "WFC = data.DataReader('WFC', 'yahoo', start, end)\n",
    "\n",
    "### Alternate for grabbing data togather\n",
    "# Data can also be retreived for a list object\n",
    "da = data.DataReader(['BAC', 'C', 'GS', 'JPM', 'MS', 'WFC'], 'yahoo', start, end)\n",
    "#### Creating a list of the ticher symbols (as string) in alphabetical order for easy reference down the line\n",
    "tickers = ['BAC', 'C', 'GS', 'JPM', 'MS', 'WFC']\n",
    "### Combing all the individual dataframes into a single dataframe\n",
    "\n",
    "bank_stocks = pd.concat(tickers, axis=1, keys=tickers)\n",
    "#Setting the column name levels. This will make it easier to differentiate the data of different banks.\n",
    "bank_stocks.columns.names = ['Bank Ticker', 'Stock Info']\n",
    "# Checking the head of the bank_stocks dataframe to see how the data looks and if concatenation is done as desired.\n",
    "bank_stock.head()\n",
    "# explorarory data analysis\n",
    "# What is the max close price for each bank's stock throughout the time period?\n",
    "bank_stock.xs(key='Close', axis=1, level='Stock Info').max()\n",
    "# What are the returns of each bank's stock\n",
    "returns = pd.DataFrame()\n",
    "\n",
    "for tick in tickers:\n",
    "    returns[tick+'Returns'] = bank_stocks[tick]['Close'].pct_change()\n",
    "returns.head()\n",
    "\n",
    "sns.pairplot(returns[1:])\n",
    "returns.idxmin()\n",
    "returns.idxmax()\n",
    "returns.std()\n",
    "returns.loc['2025-01-01':'2015-12-31'].std()\n",
    "sns.histplot(returns.loc['2015-01-01':'2015-12-31']['MS Returns'], color='green')\n",
    "sns.histplot(returns.loc['2008-01-01':'2008-12-31']['C Returns'], color='red')\n",
    "\n",
    "# Additional Import for Visualization\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Optional Plotly Method Imports\n",
    "import plotly\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "for tick in tickers:\n",
    "    bank_stocks[tick]['Close'].plot(figsize=(12,4),label=tick)\n",
    "plt.legend()\n",
    "\n",
    "# import for ploty\n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "import cufflinks as cf\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "cf.go_offline()\n",
    "\n",
    "bank_stocks.xs(key='Close',axis=1,level='Stock Info').iplot()\n",
    "# Moving Averages\n",
    "plt.figure(figsize=(12,6))\n",
    "BAC['Close'].loc['2008-01-01':'2009-01-01'].rolling(window=30).mean().plot(label='30 Day Avg')\n",
    "BAC['Close'].loc['2008-01-01':'2009-01-01'].plot(label='BAC CLOSE')\n",
    "plt.legend()\n",
    "sns.heatmap(bank_stocks.xs(key='Close',axis=1,level='Stock Info').corr(),annot=True)\n",
    "sns.clustermap(bank_stocks.xs(key='Close',axis=1,level='Stock Info').corr(),annot=True)\n",
    "close_corr = bank_stocks.xs(key='Close',axis=1,level='Stock Info').corr()\n",
    "close_corr.iplot(kind='heatmap',colorscale='rdylbu')\n",
    "#Tecnical Analisis plots\n",
    "BAC[['Open', 'High', 'Low', 'Close']].loc['2015-01-01':'2016-01-01'].iplot(kind='candle')\n",
    "MS['Close'].loc['2015-01-01':'2016-01-01'].ta_plot(study='sma',periods=[13,21,55],title='Simple Moving Averages')\n",
    "BAC['Close'].loc['2015-01-01':'2016-01-01'].ta_plot(study='boll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: public-apis\n",
      "Description: A collective list of free APIs\n",
      "Stars: 316767\n",
      "\n",
      "Name: Python\n",
      "Description: All Algorithms implemented in Python\n",
      "Stars: 193989\n",
      "\n",
      "Name: transformers\n",
      "Description: 🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.\n",
      "Stars: 134470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://api.github.com/search/repositories\",\n",
    "                        params={\"q\": \"language:python\", \"sort\": \"stars\", \"order\": \"desc\"})\n",
    "json_response = response.json()\n",
    "popular_repositories = json_response['items']\n",
    "for repo in popular_repositories[:3]:\n",
    "    print(f'Name: {repo[\"name\"]}')\n",
    "    print(f'Description: {repo[\"description\"]}')\n",
    "    print(f'Stars: {repo[\"stargazers_count\"]}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "t = requests.get(\n",
    "    \"https://api.github.com/search/repositories\", \n",
    "    [(\"q\", \"language:python\"), (\"sort\", \"stars\"), (\"order\", \"desc\")],)\n",
    "t.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dati = requests.get(\"https://api.github.com/search/repositories\", \n",
    "                    params=b\"q=language:python&sort=stars&order=desc\",)\n",
    "dati.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'real', 'indices': [59, 63]}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "    'https://api.github.com/search/repositories',\n",
    "    params = {'q':'real python'},\n",
    "    headers = {'Accept': 'applications/vnd.github.text-match+json'}\n",
    ")\n",
    "json_response = response.json()\n",
    "first_repository = json_response['items'][0]\n",
    "first_repository['text_matches'][0]['matches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "requests.get(\"https://httpbin.org/get\")\n",
    "\n",
    "requests.post(\"https://httpbin.org/post\", data={\"key\": \"value\"})\n",
    "\n",
    "requests.put(\"https://httpbin.org/put\", data={\"key\": \"value\"})\n",
    "\n",
    "requests.delete(\"https://httpbin.org/delete\")\n",
    "\n",
    "requests.head(\"https://httpbin.org/get\")\n",
    "\n",
    "requests.patch(\"https://httpbin.org/patch\", data={\"key\": \"value\"})\n",
    "\n",
    "requests.options(\"https://httpbin.org/get\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.request('GET', 'https://httpbin.org/get')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = requests.head('https://httpbin.org/get')\n",
    "response.headers['Content-Type']\n",
    "\n",
    "response = requests.delete('https://httpbin.org/delete')\n",
    "json_response = response.json()\n",
    "json_response['args']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "df = pd.DataFrame(np.random.rand(100, 5), columns=[\"a\", \"b\", \"c\", \"d\", \"e\"])\n",
    "profile = ProfileReport(df, title=\"Pandas Profiling Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install sweetviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb0735977fd4c478b6e7de8c61e19d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "                                             |          | [  0%]   00:00 -> (? left)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report SWEETVIZ_REPORT.html was generated! NOTEBOOK/COLAB USERS: the web browser MAY not pop up, regardless, the report IS saved in your notebook/colab files.\n"
     ]
    }
   ],
   "source": [
    "import sweetviz as sv\n",
    "\n",
    "my_report = sv.analyze(df)\n",
    "my_report.show_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inviare dati in un formato specifico\n",
    "\n",
    "import requests\n",
    "# inviamo dati come dizionario\n",
    "response = requests.post('https://httpbin.org/post', data={'key':'value'})\n",
    "# inviamo i dati come tuple\n",
    "response = requests.post('https://httpbin.org/post', data=[('key','value')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'application/x-www-form-urlencoded'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# inviamo dati come dizionario\n",
    "response = requests.post('https://httpbin.org/post', data={'key':'value'})\n",
    "json_response = response.json()\n",
    "json_response['data']\n",
    "json_response['headers']['Content-Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"key\": \"value\"}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "# inviamo dati come dizionario\n",
    "response = requests.post('https://httpbin.org/post', json={'key':'value'})\n",
    "#json_response = response.json()\n",
    "# inspezioniamo la risposta\n",
    "response.request.headers['Content-Type']\n",
    "response.request.url\n",
    "response.request.body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic dXNlcjpwYXNzd2Q='"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# richiesta di dati da api tramite autenticazione\n",
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "    'https://httpbin.org/basic-auth/user/passwd',\n",
    "    auth=('user', 'passwd')\n",
    ")\n",
    "\n",
    "response.status_code\n",
    "response.request.headers['Authorization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from requests.auth import HTTPBasicAuth\n",
    "\n",
    "requests.get('https://httpbin.org/basic-auth/user/passwd',\n",
    "             auth=HTTPBasicAuth('user','passwd'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [401]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://api.github.com/user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Basic OjxZT1VSX0dJVEhVQl9QQV9UT0tFTj4='"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "token = \"<YOUR_GITHUB_PA_TOKEN>\"\n",
    "response = requests.get(\n",
    "     \"https://api.github.com/user\",\n",
    "     auth=(\"\", token)\n",
    ")\n",
    "response.status_code\n",
    "response.json()\n",
    "response.request.headers['Authorization']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.auth import AuthBase\n",
    "\n",
    "class TokenAuth(AuthBase):\n",
    "    \"\"\"Implements a token authentication scheme.\"\"\"\n",
    "\n",
    "    def __init__(self, token):\n",
    "        self.token = token\n",
    "    \n",
    "    def __cal__(self, request):\n",
    "        \"\"\"Attach an API token to the Autorization header.\"\"\"\n",
    "        request.headers['Authorization'] = f'Bearer {self.token}'\n",
    "        return request\n",
    "\n",
    "token = \"<YOUR_GITHUB_PA_TOKEN>\"\n",
    "response = requests.get(\n",
    "    'https://api.github.com/user',\n",
    "    auth = TokenAuth(token)\n",
    ")\n",
    "response.status_code\n",
    "response.request.headers['Authorization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Utente\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\urllib3\\connectionpool.py:1095: InsecureRequestWarning: Unverified HTTPS request is being made to host 'api.github.com'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(\"https://api.github.com\", verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://api.github.com', timeout=1)\n",
    "requests.get('https://api.github.com', timeout=3.05)\n",
    "# connessione entro 3.05 e dati entro i 5\n",
    "requests.get('https://api.github.com', timeout=(3.05, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The request did not time out\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import Timeout\n",
    "\n",
    "try:\n",
    "    response = requests.get('https://api.github.com', timeout=(3.05, 5))\n",
    "except Timeout:\n",
    "    print('The request timed out')\n",
    "else:\n",
    "    print('The request did not time out')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from custom_token_auth import TokenAuth\n",
    "\n",
    "TOKEN = '<YOUR_GITHUB_PA_TOKEN>'\n",
    "\n",
    "with requests.Session() as session:\n",
    "    session.auth = TokenAuth(TOKEN)\n",
    "\n",
    "    first_response = session.get(\"https://api.github.com/user\")\n",
    "    second_response = session.get(\"https://api.github.com/user\")\n",
    "\n",
    "print(first_response.headers)\n",
    "print(second_response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.exceptions import RetryError\n",
    "\n",
    "github_adapter = HTTPAdapter(max_retries=2)\n",
    "\n",
    "session = requests.Session()\n",
    "\n",
    "session.mount('https://api.github.com', github_adapter)\n",
    "\n",
    "try:\n",
    "    response = session.get('https://api.github.com/')\n",
    "except RetryError as err:\n",
    "    print(f'Error: {err}')\n",
    "finally:\n",
    "    session.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#CREO UN APP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dash\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html\n",
    "\n",
    "app = Dash()\n",
    "\n",
    "app.layout = [html.Div(children='Hello World')]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table\n",
    "import pandas as pd\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash()\n",
    "\n",
    "# App layout\n",
    "app.layout = [\n",
    "    html.Div(children='My First App with Data'),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=10)\n",
    "]\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash()\n",
    "\n",
    "# App layout\n",
    "app.layout = [\n",
    "    html.Div(children='My First App with Data and a Graph'),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=10),\n",
    "    dcc.Graph(figure=px.histogram(df, x='continent', y='lifeExp', histfunc='avg'))\n",
    "]\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash()\n",
    "\n",
    "# App layout\n",
    "app.layout = [\n",
    "    html.Div(children='My First App with Data, Graph, and Controls'),\n",
    "    html.Hr(),\n",
    "    dcc.RadioItems(options=['pop', 'lifeExp', 'gdpPercap'], value='lifeExp', id='controls-and-radio-item'),\n",
    "    dash_table.DataTable(data=df.to_dict('records'), page_size=6),\n",
    "    dcc.Graph(figure={}, id='controls-and-graph')\n",
    "]\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='controls-and-graph', component_property='figure'),\n",
    "    Input(component_id='controls-and-radio-item', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app - incorporate css\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = Dash(external_stylesheets=external_stylesheets)\n",
    "\n",
    "# App layout\n",
    "app.layout = [\n",
    "    html.Div(className='row', children='My First App with Data, Graph, and Controls',\n",
    "             style={'textAlign': 'center', 'color': 'blue', 'fontSize': 30}),\n",
    "\n",
    "    html.Div(className='row', children=[\n",
    "        dcc.RadioItems(options=['pop', 'lifeExp', 'gdpPercap'],\n",
    "                       value='lifeExp',\n",
    "                       inline=True,\n",
    "                       id='my-radio-buttons-final')\n",
    "    ]),\n",
    "\n",
    "    html.Div(className='row', children=[\n",
    "        html.Div(className='six columns', children=[\n",
    "            dash_table.DataTable(data=df.to_dict('records'), page_size=11, style_table={'overflowX': 'auto'})\n",
    "        ]),\n",
    "        html.Div(className='six columns', children=[\n",
    "            dcc.Graph(figure={}, id='histo-chart-final')\n",
    "        ])\n",
    "    ])\n",
    "]\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='histo-chart-final', component_property='figure'),\n",
    "    Input(component_id='my-radio-buttons-final', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importiamo le librerie e i pacchetti\n",
    "# dcc = Dach Core Components == rendering grafici iterattivi\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Incorporiamo i dati in formato csv dal web\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "#print(df.head())\n",
    "# Inizializziamo l'app ed incorporiamo il css\n",
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']\n",
    "app = Dash(external_stylesheets=external_stylesheets) # inserisco il file di sile css\n",
    "\n",
    "# Creiamo il layout\n",
    "app.layout = [\n",
    "    html.Div(className = 'row', children='My First App with Data, Graph, and Controls',\n",
    "             style={'textAlign':'center', 'color':'blue', 'fontSize':30}), # centro, coloro e dimensione del titolo\n",
    "    \n",
    "    #scelgo le varie opzioni di select\n",
    "    html.Div(className='row', children=[\n",
    "        dcc.RadioItems(options=['pop', 'lifeExp', 'gdpPercap'],\n",
    "                       value='lifeExp',\n",
    "                       #inline='True',\n",
    "                       id='my-radio-buttons-final')\n",
    "    ]),\n",
    "\n",
    "    ## creo il div che conterrà il dataframe e l'istogramma corrispondente\n",
    "    html.Div(className='row', children=[\n",
    "        html.Div(className='six columns', children=[\n",
    "            dash_table.DataTable(data=df.to_dict('records'), page_size=11, style_table={'overflowX':'auto'})\n",
    "        ]),\n",
    "        html.Div(className='six columns', children=[\n",
    "            dcc.Graph(figure={}, id='histo-chart-final')\n",
    "        ])\n",
    "    ]),\n",
    "\n",
    "        #html.Hr(),\n",
    "        # inserisco le possibili scelte\n",
    "        #dcc.RadioItems(options=['pop', 'lifeExp', 'gdpPercap'], value='lifeExp', id = 'controls-and-radio-item'),\n",
    "        # creo una tabella con il df, specifico records per avere un dizionario per ogni caso\n",
    "        #dash_table.DataTable(data=df.to_dict('records'), page_size=6),\n",
    "        # costruisco un grafico interattivo tramite dcc.Graph, passandogli\n",
    "        # l'histogramma costruito con plotly, calcolando la media per ogni continente, x continenti, y lifeexp, \n",
    "            #dcc.Graph(figure=px.histogram(df, x='continent', y='lifeExp', histfunc='avg'))\n",
    "        #dcc.Graph(figure={}, id='controls-and-graph')\n",
    "]\n",
    "\n",
    "#Aggiungiamo i controlli per costruire le interazioni\n",
    "@callback(\n",
    "    Output(component_id='histo-chart-final', component_property='figure'),\n",
    "    Input(component_id='my-radio-buttons-final', component_property='value')\n",
    ")\n",
    "\n",
    "# creo una funzione che ritorna l'istogramma della colonna scelta\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash_design_kit\n",
      "  Downloading dash_design_kit-0.0.1-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading dash_design_kit-0.0.1-py2.py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: dash_design_kit\n",
      "Successfully installed dash_design_kit-0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#!pip install dash_design_kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages    #SERVE VERSIONE ENTERPRISE\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_design_kit as ddk\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app\n",
    "app = Dash(__name__)\n",
    "\n",
    "# App layout\n",
    "app.layout = ddk.App([\n",
    "    ddk.Header(ddk.Title('My First App with Data, Graph, and Controls')),\n",
    "    dcc.RadioItems(options=['pop', 'lifeExp', 'gdpPercap'],\n",
    "                    value='lifeExp',\n",
    "                    inline=True,\n",
    "                    id='my-ddk-radio-items-final'),\n",
    "    ddk.Row([\n",
    "        ddk.Card([\n",
    "            dash_table.DataTable(data=df.to_dict('records'), page_size=12, style_table={'overflowX': 'auto'})\n",
    "        ], width=50),\n",
    "        ddk.Card([\n",
    "            ddk.Graph(figure={}, id='graph-placeholder-ddk-final')\n",
    "        ], width=50),\n",
    "    ]),\n",
    "\n",
    "])\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='graph-placeholder-ddk-final', component_property='figure'),\n",
    "    Input(component_id='my-ddk-radio-items-final', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from dash import Dash, html, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "# Incorporate data\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "# Initialize the app - incorporate a Dash Bootstrap theme\n",
    "external_stylesheets = [dbc.themes.CERULEAN]\n",
    "app = Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "# App layout\n",
    "app.layout = dbc.Container([\n",
    "    dbc.Row([\n",
    "        html.Div('My First App with Data, Graph, and Controls', className=\"text-primary text-center fs-3\")\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.RadioItems(options=[{\"label\": x, \"value\": x} for x in ['pop', 'lifeExp', 'gdpPercap']],\n",
    "                       value='lifeExp',\n",
    "                       inline=True,\n",
    "                       id='radio-buttons-final')\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dash_table.DataTable(data=df.to_dict('records'), page_size=12, style_table={'overflowX': 'auto'})\n",
    "        ], width=6),\n",
    "\n",
    "        dbc.Col([\n",
    "            dcc.Graph(figure={}, id='my-first-graph-final')\n",
    "        ], width=6),\n",
    "    ]),\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "# Add controls to build the interaction\n",
    "@callback(\n",
    "    Output(component_id='my-first-graph-final', component_property='figure'),\n",
    "    Input(component_id='radio-buttons-final', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install dash_mantine_components==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall dash_mantine_components==0.14.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, dash_table, dcc, callback, Output, Input\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import dash_mantine_components as dmc\n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/gapminder2007.csv')\n",
    "\n",
    "app = Dash()\n",
    "\n",
    "app.layout = dmc.Container([\n",
    "    dmc.Title('My First App with Data, Graph, and Controls', color=\"blue\", size=\"h3\"),\n",
    "    dmc.RadioGroup(\n",
    "            [dmc.Radio(i, value=i) for i in  ['pop', 'lifeExp', 'gdpPercap']],\n",
    "            id='my-dmc-radio-item',\n",
    "            value='lifeExp',\n",
    "            size=\"sm\"\n",
    "        ),\n",
    "    dmc.Grid([\n",
    "        dmc.Col([\n",
    "            dash_table.DataTable(data=df.to_dict('records'), page_size=12, style_table={'overflowX': 'auto'})\n",
    "        ], span=6),\n",
    "        dmc.Col([\n",
    "            dcc.Graph(figure={}, id='graph-placeholder')\n",
    "        ], span=6),\n",
    "    ]),\n",
    "\n",
    "], fluid=True)\n",
    "\n",
    "@callback(\n",
    "    Output(component_id='graph-placeholder', component_property='figure'),\n",
    "    Input(component_id='my-dmc-radio-item', component_property='value')\n",
    ")\n",
    "def update_graph(col_chosen):\n",
    "    fig = px.histogram(df, x='continent', y=col_chosen, histfunc='avg')\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
